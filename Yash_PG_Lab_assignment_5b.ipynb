{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yash-Narnaware/PG-Lab/blob/main/Yash_PG_Lab_assignment_5b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Load and preprocess the data**"
      ],
      "metadata": {
        "id": "B_KSc-Rl60_J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-IWqLuU7qwP",
        "outputId": "bee22267-ace7-48e6-eb04-cd706e6fc986",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import gensim\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download NLTK stopwords and punkt tokenizer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b58fe9-6ed5-4bc9-e0ea-67d279152369",
        "id": "N5UUGpH-7qwh"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/IMDB Dataset.csv\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "\n",
        "    # Remove punctuation and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(text.lower())\n",
        "\n",
        "    # Remove stopwords\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Join the tokens back into a single string\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing to the 'review' column\n",
        "df['review'] = df['review'].apply(preprocess_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "ilQXK4JMaSu3",
        "outputId": "2a8fddbb-3b0f-4863-ddc0-c7256a1d48ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-f02bededea82>:6: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4103f43-c6a5-4e2d-c5ce-0042ec6aabd8",
        "id": "6UPJ52uB7qwi"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        [one, reviewers, mentioned, watching, oz, epis...\n",
            "1        [wonderful, little, production, filming, techn...\n",
            "2        [thought, wonderful, way, spend, time, hot, su...\n",
            "3        [basically, theres, family, little, boy, jake,...\n",
            "4        [petter, matteis, love, time, money, visually,...\n",
            "                               ...                        \n",
            "49995    [thought, movie, right, good, job, wasnt, crea...\n",
            "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
            "49997    [catholic, taught, parochial, elementary, scho...\n",
            "49998    [im, going, disagree, previous, comment, side,...\n",
            "49999    [one, expects, star, trek, movies, high, art, ...\n",
            "Name: review, Length: 50000, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# review_text = df.review.apply(gensim.utils.simple_preprocess)\n",
        "review_text = df['review'].apply(gensim.utils.simple_preprocess)\n",
        "print(review_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Calculate the length of each sequence (each tokenized review)\n",
        "# review_lengths = [len(review) for review in review_text]\n",
        "\n",
        "# # Compute the 90th percentile for maxlen\n",
        "# maxlen = int(np.percentile(review_lengths, 90))\n",
        "\n",
        "# print(f\"90th percentile length: {maxlen}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3nyNz6tBw1a",
        "outputId": "3819c4a8-bb71-4335-c1fd-d01bf3f49206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90th percentile length: 438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Split the data and convert labels to numbers"
      ],
      "metadata": {
        "id": "E7K9buuKFIsV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI0UHhms7DBh"
      },
      "outputs": [],
      "source": [
        "# Split data into training and testing\n",
        "train_data, test_data = train_test_split(df, test_size=0.4, random_state=42)\n",
        "\n",
        "# Tokenize text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data['review'])\n",
        "train_sequences = tokenizer.texts_to_sequences(train_data['review'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data['review'])\n",
        "\n",
        "# Padding sequences\n",
        "max_len = 438  # 90th percentile of max length\n",
        "X_train = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "X_test = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "y_train = train_data['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "y_test = test_data['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6fb465c-1160-44b1-9632-d264ac19a7f6",
        "id": "_nNcmkWP8Gpe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 438)\n",
            "(30000,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Bulding LSTM based sentiment analysis model using custom trained Word2Vec model**"
      ],
      "metadata": {
        "id": "ODnrKjz4HYzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training Word2Vec model on IMDB reviews dataset"
      ],
      "metadata": {
        "id": "Mzd9Mn_hNjbe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeaWC84rMSO4"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fh-P6r9Uf3PY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ceab2f-6c2b-4d9f-f436-386dd71d4d06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        [one, of, the, other, reviewers, has, mentione...\n",
            "1        [wonderful, little, production, br, br, the, f...\n",
            "2        [thought, this, was, wonderful, way, to, spend...\n",
            "3        [basically, there, family, where, little, boy,...\n",
            "4        [petter, mattei, love, in, the, time, of, mone...\n",
            "                               ...                        \n",
            "49995    [thought, this, movie, did, down, right, good,...\n",
            "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
            "49997    [am, catholic, taught, in, parochial, elementa...\n",
            "49998    [going, to, have, to, disagree, with, the, pre...\n",
            "49999    [no, one, expects, the, star, trek, movies, to...\n",
            "Name: review, Length: 50000, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# review_text = df.review.apply(gensim.utils.simple_preprocess)\n",
        "# review_text = df['review'].apply(gensim.utils.simple_preprocess)\n",
        "print(review_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFwokN93g28X"
      },
      "outputs": [],
      "source": [
        "# Build the custom Word2Vec model for custom training. Uses CBOW by default for training.\n",
        "custom_word2vec = gensim.models.Word2Vec(\n",
        "    vector_size=100,\n",
        "    window=10,\n",
        "    min_count=3,\n",
        "    workers=10\n",
        ")\n",
        "\n",
        "custom_word2vec.build_vocab(review_text, progress_per=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYD1JwEjirTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d22164e-4fc4-478c-8555-e2e56e3a3dfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42334325, 55882335)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "custom_word2vec.train(review_text, total_examples=custom_word2vec.corpus_count, epochs=custom_word2vec.epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoSKcB6yjTYk",
        "outputId": "d2ef8b25-c508-4e48-8892-f9c62af02056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "Word2Vec<vocab=50210, vector_size=100, alpha=0.025>\n"
          ]
        }
      ],
      "source": [
        "# custom_word2vec.wv.most_similar(\"superpower\")\n",
        "print(custom_word2vec.vector_size)\n",
        "print(custom_word2vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Building LSTM based classifier using customly trained Word2Vec model"
      ],
      "metadata": {
        "id": "0XitNhION91F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fY3wAnElBez"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####creating embedding matrix"
      ],
      "metadata": {
        "id": "8S8k_ZqMRopX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2aChAFjkx5r"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained Word2Vec model\n",
        "# word2vec = Word2Vec.load(\"word2vec.model\")\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 100\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in custom_word2vec.wv:\n",
        "        embedding_matrix[i] = custom_word2vec.wv[word]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Defining the model architecture"
      ],
      "metadata": {
        "id": "xuPAC8dWF662"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build LSTM model\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len, weights=[embedding_matrix], trainable=False))\n",
        "model1.add(LSTM(128, return_sequences=True))\n",
        "model1.add(LSTM(12))\n",
        "model1.add(Dense(20, activation='relu'))\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "i9-uU60kR1ms",
        "outputId": "5ac3e11b-a1e0-49bd-9c23-86a1366672fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │      \u001b[38;5;34m29,497,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_18 (\u001b[38;5;33mLSTM\u001b[0m)                       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_19 (\u001b[38;5;33mLSTM\u001b[0m)                       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">29,497,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,497,800\u001b[0m (112.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,497,800</span> (112.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m29,497,800\u001b[0m (112.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,497,800</span> (112.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwrtsRZsoVQI",
        "outputId": "b5c3a8ef-d404-4bce-b234-9fdff16dfa4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 59ms/step - accuracy: 0.5231 - loss: 0.6880 - val_accuracy: 0.5904 - val_loss: 0.6738\n",
            "Epoch 2/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 62ms/step - accuracy: 0.5746 - loss: 0.6783 - val_accuracy: 0.5138 - val_loss: 0.6895\n",
            "Epoch 3/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 55ms/step - accuracy: 0.5168 - loss: 0.6905 - val_accuracy: 0.5181 - val_loss: 0.6869\n",
            "Epoch 4/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 55ms/step - accuracy: 0.5755 - loss: 0.6624 - val_accuracy: 0.5785 - val_loss: 0.6595\n",
            "Epoch 5/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 69ms/step - accuracy: 0.5731 - loss: 0.6657 - val_accuracy: 0.5252 - val_loss: 0.6807\n",
            "Epoch 6/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 54ms/step - accuracy: 0.5649 - loss: 0.6666 - val_accuracy: 0.7033 - val_loss: 0.5844\n",
            "Epoch 7/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.6537 - loss: 0.6245 - val_accuracy: 0.6544 - val_loss: 0.6275\n",
            "Epoch 8/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 55ms/step - accuracy: 0.6620 - loss: 0.6146 - val_accuracy: 0.5332 - val_loss: 0.6747\n",
            "Epoch 9/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 76ms/step - accuracy: 0.5282 - loss: 0.6732 - val_accuracy: 0.5471 - val_loss: 0.6641\n",
            "Epoch 10/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 60ms/step - accuracy: 0.5460 - loss: 0.6654 - val_accuracy: 0.5005 - val_loss: 0.6948\n",
            "Epoch 11/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 63ms/step - accuracy: 0.5089 - loss: 0.6918 - val_accuracy: 0.5110 - val_loss: 0.6920\n",
            "Epoch 12/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 56ms/step - accuracy: 0.5010 - loss: 0.6917 - val_accuracy: 0.5161 - val_loss: 0.6910\n",
            "Epoch 13/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 61ms/step - accuracy: 0.5195 - loss: 0.6903 - val_accuracy: 0.5113 - val_loss: 0.6869\n",
            "Epoch 14/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 53ms/step - accuracy: 0.5079 - loss: 0.6924 - val_accuracy: 0.5171 - val_loss: 0.6898\n",
            "Epoch 15/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 55ms/step - accuracy: 0.5144 - loss: 0.6860 - val_accuracy: 0.8343 - val_loss: 0.4000\n",
            "Epoch 16/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 73ms/step - accuracy: 0.8567 - loss: 0.3522 - val_accuracy: 0.8796 - val_loss: 0.2906\n",
            "Epoch 17/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 52ms/step - accuracy: 0.8875 - loss: 0.2800 - val_accuracy: 0.8774 - val_loss: 0.2850\n",
            "Epoch 18/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 55ms/step - accuracy: 0.8940 - loss: 0.2592 - val_accuracy: 0.8936 - val_loss: 0.2630\n",
            "Epoch 19/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 58ms/step - accuracy: 0.9051 - loss: 0.2394 - val_accuracy: 0.8975 - val_loss: 0.2481\n",
            "Epoch 20/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 67ms/step - accuracy: 0.9124 - loss: 0.2218 - val_accuracy: 0.8981 - val_loss: 0.2498\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x784b457d7400>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# Train the model\n",
        "model1.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = model1.evaluate(X_test, y_test)\n",
        "print(\"Accuracy on test dataset:\",test_model[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EytwoHe_IorP",
        "outputId": "b536f165-7faa-4b8a-ec3b-f0e050bc957e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9003 - loss: 0.2436\n",
            "Accuracy on test dataset: 0.8981000185012817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp4Uz6TAyfZ8"
      },
      "source": [
        "##**Bulding LSTM based sentiment analysis model using pretrained GloVe embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "2QADHgjtUiyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###download and unzip GloVe embedding model"
      ],
      "metadata": {
        "id": "tA38NIYjT5T1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnKgUWZ8T-Jy",
        "outputId": "9e79f713-4a72-447e-8523-f23f70257fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-07 11:00:25--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-09-07 11:00:25--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2024-09-07 11:03:04 (5.18 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove*.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAhifdUTUAeu",
        "outputId": "2c8d0cc4-6138-4f25-cfd9-ed938296618c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oBeK3ZF0qnQ"
      },
      "source": [
        "###load GloVe model of 100 dimentional vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui2DX9Nlyg4L",
        "outputId": "96200e12-d5e0-4c37-e851-d5e8788d7a7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "# Load the GloVe word embeddings\n",
        "embedding_index = {}\n",
        "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_index[word] = vector\n",
        "\n",
        "print(f\"Loaded {len(embedding_index)} word vectors.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCtPYFTO0xlI"
      },
      "source": [
        "###Create embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CS3YrBEO00Zd"
      },
      "outputs": [],
      "source": [
        "# Define the word index\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Parameters\n",
        "embedding_dim = 100  # Use 100-dimensional GloVe vectors\n",
        "vocab_size = len(word_index) + 1  # word_index is from your tokenizer\n",
        "\n",
        "# Create an embedding matrix with random initialization\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "# Fill embedding matrix with GloVe vectors\n",
        "for word, idx in word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[idx] = embedding_vector  # Assign GloVe vector for the word\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Defining model architecture and training the model"
      ],
      "metadata": {
        "id": "oLtC34WMcBDd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "kGFmLbpQ2CJa",
        "outputId": "3251d01a-3d21-4346-be8e-7b02d1d8b038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │       \u001b[38;5;34m9,832,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">9,832,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,832,600\u001b[0m (37.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,832,600</span> (37.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,832,600\u001b[0m (37.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,832,600</span> (37.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Build the LSTM model with pretrained GloVe embeddings\n",
        "model2 = Sequential()\n",
        "\n",
        "# Add embedding layer initialized with GloVe embeddings\n",
        "model2.add(Embedding(input_dim=vocab_size,\n",
        "                    output_dim=embedding_dim,\n",
        "                    input_length=max_len,\n",
        "                    weights=[embedding_matrix],  # Use GloVe vectors\n",
        "                    trainable=False))  # Set to False to keep embeddings static\n",
        "\n",
        "model2.add(LSTM(128, return_sequences=True))\n",
        "model2.add(LSTM(12))\n",
        "model2.add(Dense(20, activation='relu'))\n",
        "model2.add(Dropout(0.1))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model2.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsu1Kx922pqg",
        "outputId": "1aede779-ac41-45ad-b215-ee76b8cde09e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 51ms/step - accuracy: 0.4967 - loss: 0.6934 - val_accuracy: 0.5083 - val_loss: 0.6927\n",
            "Epoch 2/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 55ms/step - accuracy: 0.5133 - loss: 0.6920 - val_accuracy: 0.4970 - val_loss: 0.6924\n",
            "Epoch 3/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.5174 - loss: 0.6900 - val_accuracy: 0.5174 - val_loss: 0.6900\n",
            "Epoch 4/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 46ms/step - accuracy: 0.5292 - loss: 0.6856 - val_accuracy: 0.7826 - val_loss: 0.5018\n",
            "Epoch 5/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 72ms/step - accuracy: 0.7969 - loss: 0.4678 - val_accuracy: 0.8537 - val_loss: 0.3534\n",
            "Epoch 6/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 45ms/step - accuracy: 0.8504 - loss: 0.3521 - val_accuracy: 0.8643 - val_loss: 0.3221\n",
            "Epoch 7/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 47ms/step - accuracy: 0.8747 - loss: 0.3082 - val_accuracy: 0.8723 - val_loss: 0.3065\n",
            "Epoch 8/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 46ms/step - accuracy: 0.8830 - loss: 0.2822 - val_accuracy: 0.8756 - val_loss: 0.2958\n",
            "Epoch 9/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 46ms/step - accuracy: 0.8946 - loss: 0.2603 - val_accuracy: 0.8765 - val_loss: 0.2939\n",
            "Epoch 10/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 51ms/step - accuracy: 0.9041 - loss: 0.2441 - val_accuracy: 0.8465 - val_loss: 0.3506\n",
            "Epoch 11/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 44ms/step - accuracy: 0.9136 - loss: 0.2201 - val_accuracy: 0.8829 - val_loss: 0.2840\n",
            "Epoch 12/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 58ms/step - accuracy: 0.9288 - loss: 0.1923 - val_accuracy: 0.8853 - val_loss: 0.2895\n",
            "Epoch 13/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 48ms/step - accuracy: 0.9403 - loss: 0.1617 - val_accuracy: 0.8783 - val_loss: 0.3243\n",
            "Epoch 14/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.9475 - loss: 0.1443 - val_accuracy: 0.8846 - val_loss: 0.3228\n",
            "Epoch 15/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 44ms/step - accuracy: 0.9574 - loss: 0.1249 - val_accuracy: 0.8852 - val_loss: 0.3367\n",
            "Epoch 16/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 53ms/step - accuracy: 0.9669 - loss: 0.1029 - val_accuracy: 0.8827 - val_loss: 0.3417\n",
            "Epoch 17/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 44ms/step - accuracy: 0.9734 - loss: 0.0845 - val_accuracy: 0.8802 - val_loss: 0.3530\n",
            "Epoch 18/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 44ms/step - accuracy: 0.9790 - loss: 0.0688 - val_accuracy: 0.8827 - val_loss: 0.4059\n",
            "Epoch 19/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 56ms/step - accuracy: 0.9816 - loss: 0.0629 - val_accuracy: 0.8759 - val_loss: 0.4719\n",
            "Epoch 20/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 43ms/step - accuracy: 0.9854 - loss: 0.0528 - val_accuracy: 0.8838 - val_loss: 0.4356\n"
          ]
        }
      ],
      "source": [
        "#training the model\n",
        "history = model2.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model2 = model2.evaluate(X_test, y_test)\n",
        "print(\"Accuracy on test dataset:\",test_model2[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1KKBJedKifY",
        "outputId": "d5b41518-bfec-4d0c-fcd2-00a7c80aecc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.8849 - loss: 0.4250\n",
            "Accuracy on test dataset: 0.8838499784469604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i81lIiLE4QBA"
      },
      "source": [
        "##**Bulding LSTM based sentiment analysis model using pretrained FastText word embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout"
      ],
      "metadata": {
        "id": "8Ks2o6-mc3LN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Download and unzip FastText embedding model"
      ],
      "metadata": {
        "id": "r0mIwVhdeKlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NEqVcmVePxl",
        "outputId": "a740b37f-7f03-46e1-b367-409c4e8ae1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-07 11:19:36--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.14, 3.163.189.51, 3.163.189.96, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  90.0MB/s    in 11s     \n",
            "\n",
            "2024-09-07 11:19:46 (60.9 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip wiki-news-300d-1M.vec*.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xym_4LtIeUCG",
        "outputId": "278a4455-382b-4f35-90f8-4ff08cb2aeb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load FastText embedding model"
      ],
      "metadata": {
        "id": "RIWUi4t5dEAe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaLA7pKK4Qy8",
        "outputId": "a715379d-310f-4aa4-fe5f-1163e6ebf708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 999995 word vectors.\n"
          ]
        }
      ],
      "source": [
        "# Initialize an empty dictionary to hold the word vectors\n",
        "embedding_index = {}\n",
        "\n",
        "# Load the FastText word embeddings file\n",
        "with open('wiki-news-300d-1M.vec', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        # Split each line into word and vector components\n",
        "        values = line.split()\n",
        "        word = values[0]  # The word\n",
        "        vector = np.asarray(values[1:], dtype='float32')  # The vector representation\n",
        "        embedding_index[word] = vector  # Add to the dictionary\n",
        "\n",
        "print(f\"Loaded {len(embedding_index)} word vectors.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create embedding matrix"
      ],
      "metadata": {
        "id": "5hjYKOpydgMK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxbIX5Vw4Xc9"
      },
      "outputs": [],
      "source": [
        "# Define embedding dimension and vocab size\n",
        "embedding_dim = 300  # Use the dimension of your FastText vectors\n",
        "vocab_size = len(word_index) + 1  # Add 1 for padding\n",
        "\n",
        "# Initialize embedding matrix with zeros\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "# Populate the embedding matrix with FastText vectors\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector  # Assign the FastText vector\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Defining model architecture and training the model"
      ],
      "metadata": {
        "id": "1Y144TAUd2sa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "eXfAUyY14Z3O",
        "outputId": "4fe12e1e-dcaa-4a08-942d-36fed12e9a8b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │      \u001b[38;5;34m29,497,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_16 (\u001b[38;5;33mLSTM\u001b[0m)                       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_17 (\u001b[38;5;33mLSTM\u001b[0m)                       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">29,497,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,497,800\u001b[0m (112.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,497,800</span> (112.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m29,497,800\u001b[0m (112.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,497,800</span> (112.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Define the LSTM model\n",
        "model3 = Sequential()\n",
        "\n",
        "# Add FastText embedding layer (set trainable=False to freeze FastText weights)\n",
        "model3.add(Embedding(input_dim=vocab_size,\n",
        "                    output_dim=embedding_dim,\n",
        "                    input_length=max_len,\n",
        "                    weights=[embedding_matrix],\n",
        "                    trainable=False))  # Keep FastText embeddings static\n",
        "\n",
        "# Add LSTM layers\n",
        "model3.add(LSTM(128, return_sequences=True))\n",
        "model3.add(LSTM(12))\n",
        "# model3.add(Dense(20, activation='relu'))\n",
        "# model3.add(Dropout(0.1))\n",
        "\n",
        "# Add a dense output layer with sigmoid activation for binary classification\n",
        "model3.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# View model summary\n",
        "model3.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwDoT8WI4am9",
        "outputId": "4ac9cdf4-6c7e-48f0-bae0-f05bbfc1e6a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 51ms/step - accuracy: 0.5250 - loss: 0.6901 - val_accuracy: 0.5292 - val_loss: 0.6836\n",
            "Epoch 2/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 59ms/step - accuracy: 0.5231 - loss: 0.6878 - val_accuracy: 0.4994 - val_loss: 0.6933\n",
            "Epoch 3/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 49ms/step - accuracy: 0.5045 - loss: 0.6931 - val_accuracy: 0.5099 - val_loss: 0.6923\n",
            "Epoch 4/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - accuracy: 0.5078 - loss: 0.6912 - val_accuracy: 0.5332 - val_loss: 0.6757\n",
            "Epoch 5/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 69ms/step - accuracy: 0.5229 - loss: 0.6792 - val_accuracy: 0.5286 - val_loss: 0.6826\n",
            "Epoch 6/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 54ms/step - accuracy: 0.5238 - loss: 0.6818 - val_accuracy: 0.5306 - val_loss: 0.6702\n",
            "Epoch 7/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 52ms/step - accuracy: 0.5478 - loss: 0.6692 - val_accuracy: 0.5349 - val_loss: 0.6645\n",
            "Epoch 8/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 55ms/step - accuracy: 0.5333 - loss: 0.6831 - val_accuracy: 0.5153 - val_loss: 0.6910\n",
            "Epoch 9/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 80ms/step - accuracy: 0.5202 - loss: 0.6910 - val_accuracy: 0.5005 - val_loss: 0.6937\n",
            "Epoch 10/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 52ms/step - accuracy: 0.5045 - loss: 0.6931 - val_accuracy: 0.5178 - val_loss: 0.6922\n",
            "Epoch 11/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 50ms/step - accuracy: 0.5119 - loss: 0.6928 - val_accuracy: 0.5006 - val_loss: 0.6975\n",
            "Epoch 12/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - accuracy: 0.5122 - loss: 0.6901 - val_accuracy: 0.5386 - val_loss: 0.6782\n",
            "Epoch 13/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.5682 - loss: 0.6777 - val_accuracy: 0.5088 - val_loss: 0.6907\n",
            "Epoch 14/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 54ms/step - accuracy: 0.5332 - loss: 0.6850 - val_accuracy: 0.5229 - val_loss: 0.6934\n",
            "Epoch 15/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 55ms/step - accuracy: 0.5505 - loss: 0.6807 - val_accuracy: 0.5239 - val_loss: 0.6842\n",
            "Epoch 16/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 55ms/step - accuracy: 0.6047 - loss: 0.6112 - val_accuracy: 0.8616 - val_loss: 0.3467\n",
            "Epoch 17/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 64ms/step - accuracy: 0.8684 - loss: 0.3245 - val_accuracy: 0.8710 - val_loss: 0.3234\n",
            "Epoch 18/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 58ms/step - accuracy: 0.8865 - loss: 0.2873 - val_accuracy: 0.8855 - val_loss: 0.2782\n",
            "Epoch 19/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 52ms/step - accuracy: 0.8898 - loss: 0.2752 - val_accuracy: 0.8862 - val_loss: 0.2845\n",
            "Epoch 20/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 64ms/step - accuracy: 0.8962 - loss: 0.2580 - val_accuracy: 0.8891 - val_loss: 0.2716\n"
          ]
        }
      ],
      "source": [
        "#Training the model\n",
        "history = model3.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVyVdV4K4dx3",
        "outputId": "87483279-4cdc-46a3-9256-f9f5030fb8e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.8888 - loss: 0.2706\n",
            "Test Accuracy: 0.8891000151634216\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model3.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "B_KSc-Rl60_J",
        "ODnrKjz4HYzk",
        "Rp4Uz6TAyfZ8",
        "i81lIiLE4QBA"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}